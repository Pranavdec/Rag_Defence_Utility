dataset,num_defenses,avg_utility,contextual_recall,answer_relevancy,faithfulness
nq,0,0.6681178882360446,0.6097082864426318,0.8766666666666668,0.6479591836734694
nq,1,0.6435284087569578,0.5561485056153334,0.8250555555555555,0.7136666666666667
nq,2,0.5633119551746527,0.37002433800082457,0.8443174603174602,0.736111111111111
nq,3,0.3935833333333333,0.035,0.9136666666666666,0.6006666666666667
pubmedqa,0,0.6658672513417097,0.5784160371791953,0.8812994227994229,0.7316666666666669
pubmedqa,1,0.601169639944613,0.5842168686911385,0.6990370370370371,0.6916031746031747
pubmedqa,2,0.5327891322546193,0.399288929269548,0.7231250786250785,0.7057344877344879
pubmedqa,3,0.44412500000000005,0.0446666666666666,0.8779206349206349,0.8124126984126986
triviaqa,0,0.6436756716717461,0.6028016214689182,0.7766666666666667,0.69
triviaqa,1,0.6206438073634871,0.5553571147834382,0.7372222222222221,0.734
triviaqa,2,0.5261293841700195,0.35905577907493624,0.7395151515151515,0.7011111111111111
triviaqa,3,0.38066666666666665,0.02,0.7386666666666666,0.76
