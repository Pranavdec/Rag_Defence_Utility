system:
  embedding_model: all-MiniLM-L6-v2
  llm:
    provider: huggingface 
    model_path: meta-llama/Llama-3.1-8B-Instruct
    device: cuda
    temperature: 0.0
    model_name: llama3
  judge_llm: llama3

paths:
  chroma_db: data/chroma_db
  results: data/results
  cache: data/raw

data:
  dataset: nq
  ingestion_size: 700
  ingestion_seed: 42
  test_size: 5
  test_seed: 123

evaluation:
  skip_deepeval: true  # Skip for faster iteration
  deepeval_max_concurrent: 5

retrieval:
  top_k: 10  # Increased to give poison more chance
  chunk_size: 512
  chunk_overlap: 50

defenses:
- name: differential_privacy
  enabled: false
  method: dp_approx
  epsilon: 3.0
  delta: 0.01
  candidate_multiplier: 3
- name: trustrag
  enabled: false
  similarity_threshold: 0.88
  rouge_threshold: 0.25
  candidate_multiplier: 3
- name: attention_filtering
  enabled: false
  model_path: meta-llama/Llama-3.1-8B-Instruct
  top_tokens: 100
  max_corruptions: 3
  threshold: 50
  device: cuda
  candidate_multiplier: 3

attack:
  mba:
    enabled: true
    M: 5  # Fewer masks = easier task
    gamma: 0.3  # Lower threshold = easier to classify as member
    num_members: 5
    num_non_members: 5
    device: cuda
    proxy_model: gpt2-xl
    enable_spelling_correction: false
    max_document_words: 500  # More context for better predictions
    seed: 42
  
  poisoned_rag:
    enabled: true
    poisoning_rate: 50  # Much higher - flood the retrieval
    num_targets: 5  # Fewer targets, more docs per target
    seed: 42
    target_start_index: 0
    diversity_level: true

ado:
  enabled: false
  user_id: test_user_001
  sentinel_model: llama3
  strategist_model: llama3
  strategist_mode: deterministic
  trust_score_decay: 0.05
