# RAG Defence Utility Configuration

system:
  embedding_model: "all-MiniLM-L6-v2"  # Fast local embedding model
  llm:
    model_name: "llama3"
    temperature: 0.0
  judge_llm: "llama3"  # LLM for evaluation metrics (RAGAS/DeepEval)

paths:
  chroma_db: "data/chroma_db"
  results: "data/results"
  cache: "data/raw"

# Data loading parameters
data:
  ingestion_size: 10000   # Number of QA pairs to load (index their gold passages)
  ingestion_seed: 42    # Random seed for selecting ingestion samples
  test_size: 50         # Number of those to use for final metrics
  test_seed: 123        # Random seed for selecting test samples

# Evaluation parameters
evaluation:
  deepeval_max_concurrent: 5  # Max concurrent evaluations for DeepEval (reduce to avoid overloading Ollama)

# Retrieval parameters
retrieval:
  top_k: 5
  chunk_size: 512
  chunk_overlap: 50
